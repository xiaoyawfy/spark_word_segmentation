{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T22:00:07.070219Z",
     "start_time": "2025-07-25T22:00:05.546194Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:00:14.362771Z",
     "start_time": "2025-07-25T22:00:07.084386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = SparkSession.builder.appName(\"Test1\").getOrCreate()\n"
   ],
   "id": "824a601c667f9751",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:00:17.763269Z",
     "start_time": "2025-07-25T22:00:14.595553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qqp_df = spark.read.csv(\"glue/QQP/train.tsv\", header=True, inferSchema=True, sep=\"\\\\t\")\n",
    "qqp_df = qqp_df.dropna()\n"
   ],
   "id": "6615a99921750c94",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:00:19.764743Z",
     "start_time": "2025-07-25T22:00:19.644106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# 合并 question1 和 question2，特征提取\n",
    "qqp_df = qqp_df.withColumn(\"text\", concat_ws(\" [SEP] \", qqp_df[\"question1\"], qqp_df[\"question2\"]))\n",
    "qqp_df.show()"
   ],
   "id": "5ab18eeb7818447d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+--------------------+--------------------+------------+--------------------+\n",
      "|    id|  qid1|  qid2|           question1|           question2|is_duplicate|                text|\n",
      "+------+------+------+--------------------+--------------------+------------+--------------------+\n",
      "|133273|213221|213222|How is the life o...|Which level of pr...|           0|How is the life o...|\n",
      "|402555|536040|536041|How do I control ...|How do you contro...|           1|How do I control ...|\n",
      "|360472|364011|490273|What causes stool...|What can cause st...|           0|What causes stool...|\n",
      "|150662|155721|  7256|What can one do a...|What do i do afte...|           1|What can one do a...|\n",
      "|183004|279958|279959|Where can I find ...|Would a second ai...|           0|Where can I find ...|\n",
      "|119056|193387|193388|How not to feel g...|I don't beleive I...|           0|How not to feel g...|\n",
      "|356863|422862| 96457|How is air traffi...|How do you become...|           0|How is air traffi...|\n",
      "|106969|147570|   787|What is the best ...|What are the top ...|           1|What is the best ...|\n",
      "|196763|297539|297540|Can I enter Unive...|University of the...|           0|Can I enter Unive...|\n",
      "|256389| 37932|371478|Do you need a pas...|How can I move to...|           0|Do you need a pas...|\n",
      "|  2442|  4853|  4854|What is the distr...|What is the count...|           0|What is the distr...|\n",
      "|233239| 71243|177376|What will be Hill...|What will be Hila...|           1|What will be Hill...|\n",
      "|  1045|  2084|  2085|What is the respo...|What is a qualifi...|           0|What is the respo...|\n",
      "| 11568| 22332| 22333|Which is the best...|Which is the best...|           1|Which is the best...|\n",
      "|114030| 54431|173745|How is being gay ...|\"Why do a lot of ...|           0|How is being gay ...|\n",
      "|198616|299893|299894|How do you thank ...|How can I go to D...|           0|How do you thank ...|\n",
      "| 54145| 95620| 95621|What are the cool...|What are some coo...|           1|What are the cool...|\n",
      "|187998|286394|286395|If you received a...|How can I contact...|           0|If you received a...|\n",
      "|221213|289541|328497|Which are the bes...|What are some of ...|           1|Which are the bes...|\n",
      "| 85734|  9827|  9171|How do I lose wei...|What is the best ...|           1|How do I lose wei...|\n",
      "+------+------+------+--------------------+--------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:35:28.110154Z",
     "start_time": "2025-07-26T07:35:28.079677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 标签转换为数值\n",
    "label_indexer = StringIndexer(inputCol=\"is_duplicate\", outputCol=\"label\")\n",
    "\n",
    "# 文本预处理 + 特征工程\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# 模型定义（Logistic Regression）\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=20)\n",
    "\n",
    "# 构建 Pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    label_indexer,\n",
    "    tokenizer,\n",
    "    remover,\n",
    "    vectorizer,\n",
    "    idf,\n",
    "    lr\n",
    "])\n",
    "\n",
    "# 划分数据集\n",
    "qqp_train, qqp_test = qqp_df.randomSplit([0.8, 0.2], seed=42)\n"
   ],
   "id": "418febf8cea36d82",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:35:46.996217Z",
     "start_time": "2025-07-26T07:35:29.238592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 拟合模型\n",
    "qqp_model = pipeline.fit(qqp_train)\n"
   ],
   "id": "51fa7d29a249b1dd",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:35:48.842654Z",
     "start_time": "2025-07-26T07:35:48.782789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 预测\n",
    "qqp_predictions = qqp_model.transform(qqp_test)"
   ],
   "id": "d7142a206a21427",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:35:51.021450Z",
     "start_time": "2025-07-26T07:35:50.213993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 评估模型\n",
    "qqp_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_duplicate\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "qqp_accuracy = qqp_evaluator.evaluate(qqp_predictions)"
   ],
   "id": "ecc5e414557ada18",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:35:51.838470Z",
     "start_time": "2025-07-26T07:35:51.834488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出结果\n",
    "print(f\"QQP Accuracy: {qqp_accuracy:.4f}\")"
   ],
   "id": "cbe8283119c27758",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQP Accuracy: 0.7349\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:36:05.916662Z",
     "start_time": "2025-07-26T07:36:05.828455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MRPC\n",
    "mrpc_df = spark.read.csv(\"glue/MRPC/msr_paraphrase_train.txt\", header=True, inferSchema=True, sep=\"\\\\t\")\n",
    "mrpc_df = mrpc_df.dropna()\n",
    "mrpc_df = (mrpc_df.withColumnRenamed(\"Quality\", \"label\")\n",
    "           .withColumnRenamed(\"#1 String\", \"text1\")\n",
    "           .withColumnRenamed(\"#2 String\", \"text2\")\n",
    "           .withColumnRenamed(\"#1 ID\", \"id1\")\n",
    "           .withColumnRenamed(\"#2 ID\", \"id2\"))\n",
    "mrpc_df.show()"
   ],
   "id": "eb41840a82974c02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+--------------------+--------------------+\n",
      "|label|    id1|    id2|               text1|               text2|\n",
      "+-----+-------+-------+--------------------+--------------------+\n",
      "|    1| 702876| 702977|\"Amrozi accused h...|\"Referring to him...|\n",
      "|    0|2108705|2108831|Yucaipa owned Dom...|Yucaipa bought Do...|\n",
      "|    1|1330381|1330521|They had publishe...|On June 10, the s...|\n",
      "|    0|3344667|3344648|Around 0335 GMT, ...|Tab shares jumped...|\n",
      "|    1|1236820|1236712|The stock rose $2...|PG&E Corp. shares...|\n",
      "|    1| 738533| 737951|Revenue in the fi...|With the scandal ...|\n",
      "|    0| 264589| 264502|The Nasdaq had a ...|The tech-laced Na...|\n",
      "|    1| 579975| 579810|The DVD-CCA then ...|The DVD CCA appea...|\n",
      "|    0|3114205|3114194|That compared wit...|Earnings were aff...|\n",
      "|    1|1355540|1355592|He said the foods...|The foodservice p...|\n",
      "|    0| 222621| 222514|Shares of Genente...|Shares of Xoma fe...|\n",
      "|    0|3131772|3131625|Legislation makin...|Legislation makin...|\n",
      "|    0|  58747|  58516|The Nasdaq compos...|The Nasdaq Compos...|\n",
      "|    1|1464126|1464107|But he added grou...|De Sole said in t...|\n",
      "|    1| 771416| 771467|He told The Sun n...|\"Saddam's daughte...|\n",
      "|    0|1286053|1286069|Rudder was most r...|Senior Vice Presi...|\n",
      "|    0|1563874|1563853|As well as the do...|Internal chaos ha...|\n",
      "|    0|2029631|2029565|Magnarelli said R...|His wife said he ...|\n",
      "|    1|2150265|2150184|\"Sheena Young of ...|\"Sheena Young, a ...|\n",
      "|    0|2044342|2044457|I think you'll se...|I think you'll se...|\n",
      "+-----+-------+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:36:38.190327Z",
     "start_time": "2025-07-26T07:36:38.144844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 分词器\n",
    "tokenizer1 = Tokenizer(inputCol=\"text1\", outputCol=\"words1\")\n",
    "tokenizer2 = Tokenizer(inputCol=\"text2\", outputCol=\"words2\")\n",
    "\n",
    "# 停用词\n",
    "remover1 = StopWordsRemover(inputCol=\"words1\", outputCol=\"filtered1\")\n",
    "remover2 = StopWordsRemover(inputCol=\"words2\", outputCol=\"filtered2\")\n",
    "\n",
    "# TF\n",
    "tf1 = HashingTF(inputCol=\"filtered1\", outputCol=\"rawFeatures1\", numFeatures=2000)\n",
    "tf2 = HashingTF(inputCol=\"filtered2\", outputCol=\"rawFeatures2\", numFeatures=2000)\n",
    "\n",
    "# IDF\n",
    "idf1 = IDF(inputCol=\"rawFeatures1\", outputCol=\"features1\")\n",
    "idf2 = IDF(inputCol=\"rawFeatures2\", outputCol=\"features2\")\n",
    "\n",
    "# 特征拼接\n",
    "assembler = VectorAssembler(inputCols=[\"features1\", \"features2\"], outputCol=\"features\")\n",
    "\n",
    "# 逻辑回归\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer1, tokenizer2,\n",
    "    remover1, remover2,\n",
    "    tf1, tf2,\n",
    "    idf1, idf2,\n",
    "    assembler,\n",
    "    lr\n",
    "])\n"
   ],
   "id": "d83448072d416bef",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:36:42.461624Z",
     "start_time": "2025-07-26T07:36:41.460225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 划分训练/测试集\n",
    "train_df, test_df = mrpc_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 训练模型\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# 预测\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# 评估\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"MRPC Accuracy: {accuracy:.4f}\")"
   ],
   "id": "8c6e7cf07a8b0709",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC Accuracy: 0.5808\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:38:49.202336Z",
     "start_time": "2025-07-26T07:38:49.129763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# STS-B\n",
    "sts_df = spark.read.csv(\"glue/STS-B/train.tsv\", header=True, inferSchema=True, sep=\"\\\\t\")\n",
    "sts_df = sts_df.dropna()\n",
    "sts_df.printSchema()"
   ],
   "id": "b3e43511dd1f2b05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- old_index: integer (nullable = true)\n",
      " |-- source1: string (nullable = true)\n",
      " |-- source2: string (nullable = true)\n",
      " |-- sentence1: string (nullable = true)\n",
      " |-- sentence2: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:39:46.005594Z",
     "start_time": "2025-07-26T07:39:44.138127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sts_df = sts_df.select(\"sentence1\", \"sentence2\", \"score\")\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 分词\n",
    "tokenizer1 = Tokenizer(inputCol=\"sentence1\", outputCol=\"words1\")\n",
    "tokenizer2 = Tokenizer(inputCol=\"sentence2\", outputCol=\"words2\")\n",
    "\n",
    "# 去停用词\n",
    "remover1 = StopWordsRemover(inputCol=\"words1\", outputCol=\"filtered1\")\n",
    "remover2 = StopWordsRemover(inputCol=\"words2\", outputCol=\"filtered2\")\n",
    "\n",
    "# HashingTF\n",
    "tf1 = HashingTF(inputCol=\"filtered1\", outputCol=\"tf1\", numFeatures=2000)\n",
    "tf2 = HashingTF(inputCol=\"filtered2\", outputCol=\"tf2\", numFeatures=2000)\n",
    "\n",
    "# IDF\n",
    "idf1 = IDF(inputCol=\"tf1\", outputCol=\"vec1\")\n",
    "idf2 = IDF(inputCol=\"tf2\", outputCol=\"vec2\")\n",
    "\n",
    "# 拼接特征\n",
    "assembler = VectorAssembler(inputCols=[\"vec1\", \"vec2\"], outputCol=\"features\")\n",
    "\n",
    "# 线性回归\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"score\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer1, tokenizer2,\n",
    "    remover1, remover2,\n",
    "    tf1, tf2,\n",
    "    idf1, idf2,\n",
    "    assembler,\n",
    "    lr\n",
    "])\n",
    "\n",
    "train_df, test_df = sts_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "model = pipeline.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# 评估 RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n"
   ],
   "id": "220fbc4469909c42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.7341\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:40:19.502870Z",
     "start_time": "2025-07-26T07:40:17.083028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 计算 Pearson 和 Spearman 相关系数\n",
    "preds = predictions.select(\"score\", \"prediction\").toPandas()\n",
    "y_true = preds[\"score\"].values\n",
    "y_pred = preds[\"prediction\"].values\n",
    "import numpy as np\n",
    "pearson_corr = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "print(f\"Pearson correlation: {pearson_corr:.4f}\")\n",
    "from scipy.stats import spearmanr\n",
    "spearman_corr, _ = spearmanr(y_true, y_pred)\n",
    "print(f\"Spearman correlation: {spearman_corr:.4f}\")\n"
   ],
   "id": "3250420390510ad1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: -0.0005\n",
      "Spearman correlation: 0.0126\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
